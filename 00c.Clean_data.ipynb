{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import time\n",
    "from time import sleep\n",
    "from datetime import date, timedelta\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from os import path\n",
    "from pathlib import Path\n",
    "import fitz  # PyMuPDF\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path('/Users/saracaicedo/Library/CloudStorage/OneDrive-Universidaddelosandes/2025-1/Tesis')\n",
    "textCR_path = os.path.join(root,\"input/Text_CR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "textCR_path = os.path.join(root,\"input/Text_CR\" )\n",
    "text_path = os.path.join(textCR_path,\"29-11-1979.txt\")\n",
    "text_page = open(\"/Users/saracaicedo/Library/CloudStorage/OneDrive-Universidaddelosandes/2025-1/Tesis/input/Text_CR/29-11-1979.txt\", \"r\")\n",
    "text_page = text_page.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [\n",
    "    \"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \"California\", \"Colorado\", \"Connecticut\", \"Delaware\", \"Florida\", \n",
    "    \"Georgia\", \"Hawaii\", \"Idaho\", \"Illinois\", \"Indiana\", \"Iowa\", \"Kansas\", \"Kentucky\", \"Louisiana\", \"Maine\", \"Maryland\", \n",
    "    \"Massachusetts\", \"Michigan\", \"Minnesota\", \"Mississippi\", \"Missouri\", \"Montana\", \"Nebraska\", \"Nevada\", \"New Hampshire\", \n",
    "    \"New Jersey\", \"New Mexico\", \"New York\", \"North Carolina\", \"North Dakota\", \"Ohio\", \"Oklahoma\", \"Oregon\", \"Pennsylvania\", \n",
    "    \"Rhode Island\", \"South Carolina\", \"South Dakota\", \"Tennessee\", \"Texas\", \"Utah\", \"Vermont\", \"Virginia\", \"Washington\", \n",
    "    \"West Virginia\", \"Wisconsin\", \"Wyoming\"\n",
    "]\n",
    "\n",
    "# Join the states into a single regex pattern\n",
    "state_pattern = \"|\".join(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_transcript(final_text):\n",
    "    #Define the pattern to identify speakers\n",
    "    speaker_pattern = rf'(Mr\\. [A-Z]{{3,}}\\.|Mr\\. [A-Z]{{3,}} of (?:{state_pattern})\\.|The SPEAKER\\. |The VICE PRESIDENT. |The PRESIDING OFFICER )'\n",
    "\n",
    "    #Split the final text \n",
    "    split_text = re.split(speaker_pattern,final_text)\n",
    "\n",
    "    #Initialize an empty list to store the results :))\n",
    "    data = []\n",
    "\n",
    "    # Create a list of current speakers and current speeches to match them\n",
    "    current_speaker = None\n",
    "    current_speech = []\n",
    "\n",
    "    for segment in split_text :\n",
    "        if re.match(speaker_pattern, segment):\n",
    "            # If the segment in the split segment is a speaker, save the previousÂ´s speech if any\n",
    "            if current_speaker and current_speech:\n",
    "                data.append({\"speaker\": current_speaker, \"speech\": \" \".join(current_speech).strip()}) # Strip trims the strings\n",
    "            \n",
    "            # Update curent speaker and reset current speech\n",
    "            current_speaker = segment.strip()\n",
    "            current_speech = []\n",
    "\n",
    "        else:\n",
    "            #Append the sempent to the current speech if the segment was not a speaker, but a speech\n",
    "            current_speech.append(segment)\n",
    "    \n",
    "    #Add the last speakers's speech to the data\n",
    "    if current_speaker and current_speech:\n",
    "        data.append({\"speaker\": current_speaker, \"speech\": \" \".join(current_speech).strip()})\n",
    "    df = pd.DataFrame(data, columns=[\"speaker\", \"speech\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      year  month  day chamber                speaker  \\\n",
      "0     1979      9   13   upper          Mr. PACKWOOD.   \n",
      "1     1979      9   13   upper            Mr. MUSKIE.   \n",
      "2     1979      9   13   upper            Mr. MUSKIE.   \n",
      "3     1979      9   13   upper          Mr. HATFIELD.   \n",
      "4     1979      9   13   upper            Mr. MUSKIE.   \n",
      "...    ...    ...  ...     ...                    ...   \n",
      "9045  1979     10   17   upper            Mr. MORGAN.   \n",
      "9046  1979     10   17   upper          Mr. PROXMIRE.   \n",
      "9047  1979     10   17   upper          Mr. PROXMIRE.   \n",
      "9048  1979     10   17   upper  The PRESIDING OFFICER   \n",
      "9049  1979     10   17   upper  The PRESIDING OFFICER   \n",
      "\n",
      "                                                 speech  \n",
      "0     Mr. President, yield back my time.  ROUTINE MO...  \n",
      "1     I ask unanimous con; sent that the order for t...  \n",
      "2     Mr. President, I ask unanimous consent that Mi...  \n",
      "3                 Mr. President, wil the Senator yield?  \n",
      "4                                              I yield.  \n",
      "...                                                 ...  \n",
      "9045  Mr. President, I will from time to time be cal...  \n",
      "9046  Mr. President, the announcement that the Nobel...  \n",
      "9047  Mr. President, years ago President Harry Truma...  \n",
      "9048  (N MELCHER). The clerk will call the roll.  Th...  \n",
      "9049  (\\ MEtcHER). The Chair, on behalf of ti Vice P...  \n",
      "\n",
      "[9050 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd  # Import pandas for DataFrame handling\n",
    "\n",
    "# Define the path to the folder containing the text files\n",
    "textCR_path = os.path.join(root,\"input/Text_CR\")\n",
    "\n",
    "# Initialize an empty list to store all data_speech dictionaries\n",
    "all_data_speeches = []\n",
    "\n",
    "# Loop through each .txt file in the folder\n",
    "for text_file in glob.glob(os.path.join(textCR_path, \"*.txt\")):\n",
    "    # Open and read the text file\n",
    "    with open(text_file, \"r\", encoding=\"utf-8\") as file:\n",
    "        text_page = file.read()\n",
    "\n",
    "    # Process the text\n",
    "    text_page = text_page.replace('-\\n', \"\")  # Unify split words\n",
    "    text_page = text_page.replace('\\n', \" \")  # Replace newlines with spaces\n",
    "    text_page = text_page.replace(\"Mr,\", \"Mr.\")  # Fix typo\n",
    "\n",
    "    # Process the transcript (assuming process_transcript is defined elsewhere)\n",
    "    data_speech = process_transcript(text_page)\n",
    "\n",
    "    # Extract day, month, and year from the filename (assuming format: DD-MM-YYYY.txt)\n",
    "    filename = os.path.basename(text_file)\n",
    "    day, month, year = map(int, filename.split(\".\")[0].split(\"-\"))\n",
    "\n",
    "    # Add metadata to the data_speech dictionary\n",
    "    data_speech[\"day\"] = day\n",
    "    data_speech[\"month\"] = month\n",
    "    data_speech[\"year\"] = year\n",
    "    data_speech[\"chamber\"] = \"upper\"\n",
    "\n",
    "    # Reorder columns\n",
    "    data_speech = data_speech[['year', 'month', 'day', 'chamber', 'speaker', 'speech']]\n",
    "\n",
    "    # Append the processed data_speech to the list\n",
    "    all_data_speeches.append(data_speech)\n",
    "\n",
    "# Combine all data_speech dictionaries into a single DataFrame\n",
    "final_data_speech = pd.concat(all_data_speeches, ignore_index=True)\n",
    "\n",
    "# Now `final_data_speech` contains all the processed data\n",
    "print(final_data_speech)  # Replace this with your desired output logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = os.path.join(root,\"input/database_CR/1979.csv\")\n",
    "final_data_speech.to_csv(csv_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
